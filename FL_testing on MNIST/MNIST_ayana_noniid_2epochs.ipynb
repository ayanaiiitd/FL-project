{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data distribution among two clients and testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_indices_client1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 84\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m    Creates a subset of the dataset based on the provided indices.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m        Subset object containing the specified indices.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Subset(dataset, indices)\n\u001b[1;32m---> 84\u001b[0m subset_client1 \u001b[38;5;241m=\u001b[39m create_subsets(dataset_all, \u001b[43mtrain_indices_client1\u001b[49m)\n\u001b[0;32m     85\u001b[0m subset_client2 \u001b[38;5;241m=\u001b[39m create_subsets(dataset_all, train_indices_client2)\n\u001b[0;32m     86\u001b[0m subset_val_client1 \u001b[38;5;241m=\u001b[39m create_subsets(dataset_all, val_indices_client1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_indices_client1' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Define transformations\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((14, 14)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "dataset_all = ImageFolder('Ayana_Bharti/train_mnist_all', transform=data_transform)\n",
    "\n",
    "# Organize dataset indices by class\n",
    "def organize_indices_by_class(dataset):\n",
    "    \"\"\"\n",
    "    Organize dataset indices by their class labels.\n",
    "    \n",
    "    Args:\n",
    "        dataset: The dataset with labels to split.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with class labels as keys and corresponding indices as values.\n",
    "    \"\"\"\n",
    "    class_indices = defaultdict(list)\n",
    "    for idx, data in enumerate(dataset):\n",
    "        _, label = data\n",
    "        class_indices[label].append(idx)\n",
    "    return class_indices\n",
    "\n",
    "\n",
    "# Split dataset for non-IID simulation\n",
    "def split_dataset_for_non_iid(class_indices, val_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Splits the dataset into non-IID training and validation indices for clients.\n",
    "\n",
    "    Args:\n",
    "        class_indices: Dictionary of class label -> list of sample indices.\n",
    "        val_ratio: Proportion of samples to reserve for validation.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of train and validation indices for each client and the test set.\n",
    "    \"\"\"\n",
    "    train_indices_client1, train_indices_client2, test_indices = [], [], []\n",
    "    val_indices_client1, val_indices_client2 = [], []\n",
    "\n",
    "    for label in range(10):  # MNIST classes: 0-9\n",
    "        class_samples = class_indices[label]\n",
    "        if not class_samples:\n",
    "            continue  # Skip empty classes\n",
    "        class_split = int(val_ratio * len(class_samples))\n",
    "        class_split = max(1, class_split)  # Ensure at least 1 sample for validation if possible\n",
    "\n",
    "        if label in [0, 1, 2]:  # Client 1 classes\n",
    "            val_indices_client1.extend(class_samples[:class_split])\n",
    "            train_indices_client1.extend(class_samples[class_split:])\n",
    "        elif label in [3, 4, 5]:  # Client 2 classes\n",
    "            val_indices_client2.extend(class_samples[:class_split])\n",
    "            train_indices_client2.extend(class_samples[class_split:])\n",
    "        elif label in [6, 7, 8]:  # Test set classes\n",
    "            test_indices.extend(class_samples)\n",
    "\n",
    "    return train_indices_client1, train_indices_client2, val_indices_client1, val_indices_client2, test_indices\n",
    "\n",
    "# Create Subsets\n",
    "def create_subsets(dataset, indices):\n",
    "    \"\"\"\n",
    "    Creates a subset of the dataset based on the provided indices.\n",
    "    \n",
    "    Args:\n",
    "        dataset: The complete dataset.\n",
    "        indices: List of indices to include in the subset.\n",
    "        \n",
    "    Returns:\n",
    "        Subset object containing the specified indices.\n",
    "    \"\"\"\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "\n",
    "\n",
    "# DataLoaders\n",
    "def create_dataloader(subset, batch_size=64, shuffle=True):\n",
    "    \"\"\"\n",
    "    Creates a DataLoader for the provided dataset subset.\n",
    "    \n",
    "    Args:\n",
    "        subset: The dataset subset.\n",
    "        batch_size: Number of samples per batch.\n",
    "        shuffle: Whether to shuffle the data.\n",
    "        \n",
    "    Returns:\n",
    "        DataLoader object.\n",
    "    \"\"\"\n",
    "    if len(subset) == 0:\n",
    "        raise ValueError(\"Subset is empty. Ensure data split logic is correct.\")\n",
    "    return DataLoader(subset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# Organize indices by class\n",
    "class_indices = organize_indices_by_class(dataset_all)\n",
    "\n",
    "# Split dataset for non-IID simulation\n",
    "train_indices_client1, train_indices_client2, val_indices_client1, val_indices_client2 = split_dataset_for_non_iid(class_indices, val_ratio=0.2)\n",
    "\n",
    "# Create Subsets\n",
    "subset_client1 = create_subsets(dataset_all, train_indices_client1)\n",
    "subset_client2 = create_subsets(dataset_all, train_indices_client2)\n",
    "subset_val_client1 = create_subsets(dataset_all, val_indices_client1)\n",
    "subset_val_client2 = create_subsets(dataset_all, val_indices_client2)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 64\n",
    "loader_client1 = create_dataloader(subset_client1, batch_size=batch_size, shuffle=True)\n",
    "loader_client2 = create_dataloader(subset_client2, batch_size=batch_size, shuffle=True)\n",
    "val_loader_client1 = create_dataloader(subset_val_client1, batch_size=batch_size, shuffle=False)\n",
    "val_loader_client2 = create_dataloader(subset_val_client2, batch_size=batch_size, shuffle=False)\n",
    "test_loader = create_dataloader(dataset_all, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Summary of Data Distribution\n",
    "print(f\"Client 1 training samples: {len(subset_client1)}, validation samples: {len(subset_val_client1)}\")\n",
    "print(f\"Client 2 training samples: {len(subset_client2)}, validation samples: {len(subset_val_client2)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=14 * 14, hidden_sizes=(128, 64), output_size=9, dropout=0.2):\n",
    "        \"\"\"\n",
    "        A flexible Multi-Layer Perceptron (MLP) for non-IID federated learning.\n",
    "\n",
    "        Parameters:\n",
    "        - input_size: Size of the flattened input (default is 14*14 for MNIST-like data).\n",
    "        - hidden_sizes: Tuple defining the sizes of the hidden layers.\n",
    "        - output_size: Number of output classes (default is 10).\n",
    "        - dropout: Dropout probability to mitigate overfitting (default is 0.2).\n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], output_size)\n",
    "\n",
    "        # Add dropout layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Add optional batch normalization\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_sizes[0])\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_sizes[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "\n",
    "        Parameters:\n",
    "        - x: Input tensor of shape (batch_size, input_size).\n",
    "\n",
    "        Returns:\n",
    "        - logits: Output predictions before softmax.\n",
    "        \"\"\"\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "\n",
    "        # First layer with batch normalization\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Second layer with batch normalization\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Output layer (logits, no activation)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_local_model(model, dataloader, num_epochs, learning_rate, device='cpu'):\n",
    "#     \"\"\"\n",
    "#     Trains a local model on a client's dataset in a non-IID setup.\n",
    "\n",
    "#     Parameters:\n",
    "#     - model: The neural network to train.\n",
    "#     - dataloader: DataLoader containing the client's training data.\n",
    "#     - num_epochs: Number of epochs to train the model.\n",
    "#     - learning_rate: Learning rate for the optimizer.\n",
    "#     - device: The device to train on ('cpu' or 'cuda').\n",
    "\n",
    "#     Returns:\n",
    "#     - model: The locally trained model.\n",
    "#     \"\"\"\n",
    "#     model.to(device)  # Move the model to the specified device\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()  # Set the model to training mode\n",
    "#         total_loss = 0.0\n",
    "#         correct = 0\n",
    "#         total_samples = 0\n",
    "\n",
    "#         for inputs, labels in dataloader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)  # Move data to the same device as the model\n",
    "\n",
    "#             optimizer.zero_grad()  # Clear the gradients\n",
    "#             outputs = model(inputs)  # Forward pass\n",
    "#             loss = criterion(outputs, labels)  # Compute the loss\n",
    "#             loss.backward()  # Backpropagate the gradients\n",
    "#             optimizer.step()  # Update the weights\n",
    "\n",
    "#             total_loss += loss.item()  # Sum up the batch loss\n",
    "#             _, predicted = torch.max(outputs, 1)  # Get predictions\n",
    "#             correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "#             total_samples += labels.size(0)  # Update total samples\n",
    "\n",
    "#         # Compute average loss and accuracy for the epoch\n",
    "#         avg_loss = total_loss / len(dataloader)\n",
    "#         accuracy = correct / total_samples * 100\n",
    "#         print(f\"Client Training - Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "# def train_clients(client_models, client_dataloaders, num_epochs, learning_rate, device='cpu'):\n",
    "#     \"\"\"\n",
    "#     Trains each client's model on its respective dataset.\n",
    "\n",
    "#     Parameters:\n",
    "#     - client_models: Dictionary of client_id -> model.\n",
    "#     - client_dataloaders: Dictionary of client_id -> DataLoader.\n",
    "#     - num_epochs: Number of epochs for local training.\n",
    "#     - learning_rate: Learning rate for the optimizer.\n",
    "#     - device: The device to train on ('cpu' or 'cuda').\n",
    "\n",
    "#     Returns:\n",
    "#     - updated_client_models: Dictionary of client_id -> locally trained model.\n",
    "#     \"\"\"\n",
    "#     updated_client_models = {}\n",
    "\n",
    "#     for client_id, model in client_models.items():\n",
    "#         print(f\"\\nTraining model for Client {client_id}...\")\n",
    "#         updated_model = train_local_model(model, client_dataloaders[client_id], num_epochs, learning_rate, device)\n",
    "#         updated_client_models[client_id] = updated_model\n",
    "\n",
    "#     return updated_client_models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, num_epochs, learning_rate, val_loader=None, device='cpu'):\n",
    "    \"\"\"\n",
    "    Trains a PyTorch model using the provided dataloader, loss function, and optimizer.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The neural network to train.\n",
    "    - dataloader: DataLoader containing the training data.\n",
    "    - num_epochs: Number of epochs to train the model.\n",
    "    - learning_rate: Learning rate for the optimizer.\n",
    "    - val_loader: DataLoader for validation data (optional).\n",
    "    - device: The device to train on ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "    - model: The trained model.\n",
    "    \"\"\"\n",
    "    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)  # Move the model to the specified device\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the same device as the model\n",
    "\n",
    "            optimizer.zero_grad()  # Clear the gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute the loss\n",
    "            loss.backward()  # Backpropagate the gradients\n",
    "            optimizer.step()  # Update the weights\n",
    "\n",
    "            total_loss += loss.item()  # Sum up the batch loss\n",
    "            _, predicted = torch.max(outputs, 1)  # Get predictions\n",
    "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "            total_samples += labels.size(0)  # Update total samples\n",
    "\n",
    "        # Compute average loss and accuracy\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct / total_samples * 100\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        # Optional validation metrics\n",
    "        if val_loader:\n",
    "            val_accuracy, val_loss = evaluate_model(model, val_loader, criterion, device)\n",
    "            print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(models, dataloaders, criterion, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluates multiple models on their respective validation sets.\n",
    "    \n",
    "    Args:\n",
    "        models (dict): Dictionary of model instances (e.g., {'client1': model1, 'client2': model2}).\n",
    "        dataloaders (dict): Dictionary of corresponding dataloaders (e.g., {'client1': loader1, 'client2': loader2}).\n",
    "        criterion (torch.nn.Module): Loss function.\n",
    "        device (str): Device to run evaluation on ('cpu' or 'cuda').\n",
    "    \n",
    "    Returns:\n",
    "        dict: Performance metrics for each model (e.g., accuracy, loss).\n",
    "    \"\"\"\n",
    "    performance = {}\n",
    "    for client_id, model in models.items():\n",
    "        model.to(device)\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        dataloader = dataloaders[client_id]\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct / total_samples\n",
    "        performance[client_id] = {'accuracy': accuracy, 'loss': avg_loss}\n",
    "\n",
    "    return performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_dataset_diversity(client_dataloaders):\n",
    "    \"\"\"\n",
    "    Visualizes the label distribution across client datasets in a non-IID setup.\n",
    "\n",
    "    Args:\n",
    "    - client_dataloaders: Dictionary of client_id -> DataLoader.\n",
    "    \"\"\"\n",
    "    label_distribution = defaultdict(list)\n",
    "\n",
    "    for client_id, dataloader in client_dataloaders.items():\n",
    "        labels = []\n",
    "        for _, label_batch in dataloader:\n",
    "            labels.extend(label_batch.numpy())  # Collect all labels from the DataLoader\n",
    "\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        for u, c in zip(unique, counts):\n",
    "            label_distribution[u].append((client_id, c))\n",
    "\n",
    "    # Visualize the distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for label, distributions in label_distribution.items():\n",
    "        clients, counts = zip(*distributions)\n",
    "        plt.bar(clients, counts, label=f\"Label {label}\")\n",
    "\n",
    "    plt.xlabel(\"Clients\")\n",
    "    plt.ylabel(\"Sample Count\")\n",
    "    plt.title(\"Label Distribution Across Clients (Non-IID)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### server averaging function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def server_averaging_non_iid(client_models, client_weights=None, device='cpu'):\n",
    "#     \"\"\"\n",
    "#     Averages the parameters of multiple client models to create a global model for the non-IID scenario.\n",
    "\n",
    "#     Parameters:\n",
    "#     - client_models: List of trained local models (e.g., [model_all1, model_all2]).\n",
    "#     - client_weights (optional): List of weights corresponding to the contribution of each client model.\n",
    "#       If not provided, equal weights are assumed.\n",
    "#     - device: The device ('cpu' or 'cuda') to perform computations on.\n",
    "\n",
    "#     Returns:\n",
    "#     - global_model: The globally averaged model.\n",
    "#     \"\"\"\n",
    "#     if len(client_models) < 2:\n",
    "#         raise ValueError(\"At least two models are required for averaging.\")\n",
    "\n",
    "#     # Initialize the global model\n",
    "#     global_model = MLP().to(device)\n",
    "#     averaged_params = {}\n",
    "\n",
    "#     # Extract parameters and move to the specified device\n",
    "#     client_state_dicts = [model.state_dict() for model in client_models]\n",
    "\n",
    "#     # Use equal weights if none are provided\n",
    "#     if client_weights is None:\n",
    "#         client_weights = [1.0 / len(client_models)] * len(client_models)\n",
    "\n",
    "#     # Parameter Averaging (weighted)\n",
    "#     for key in client_state_dicts[0]:  # Iterate over the parameter keys\n",
    "#         weighted_sum = sum(client_weights[i] * client_state_dicts[i][key] for i in range(len(client_models)))\n",
    "#         averaged_params[key] = weighted_sum\n",
    "\n",
    "#     # Load averaged parameters into the global model\n",
    "#     global_model.load_state_dict(averaged_params)\n",
    "\n",
    "#     # Save the global model parameters to a file\n",
    "#     os.makedirs('textfiles', exist_ok=True)  # Ensure the directory exists\n",
    "#     torch.save(global_model.state_dict(), 'textfiles/server_non_iid.txt')\n",
    "\n",
    "#     return global_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def server_averaging(*local_models, device='cpu'):\n",
    "#     \"\"\"\n",
    "#     Averages the parameters of multiple local models to create a global model.\n",
    "\n",
    "#     Parameters:\n",
    "#     - *local_models: Variable number of trained local models (e.g., model_all1, model_all2).\n",
    "#     - device: The device ('cpu' or 'cuda') to perform computations on.\n",
    "\n",
    "#     Returns:\n",
    "#     - server_model: The globally averaged model.\n",
    "#     \"\"\"\n",
    "#     if len(local_models) < 2:\n",
    "#         raise ValueError(\"At least two models are required for averaging.\")\n",
    "    \n",
    "#     # Initialize the global model\n",
    "#     server_model = MLP().to(device)\n",
    "#     averaged_params = {}\n",
    "\n",
    "#     # Extract parameters and move to the specified device\n",
    "#     local_state_dicts = [model.state_dict() for model in local_models]\n",
    "\n",
    "#     # Parameter Averaging\n",
    "#     for key in local_state_dicts[0]:  # Iterate over the parameter keys\n",
    "#         averaged_params[key] = sum(local_state_dict[key] for local_state_dict in local_state_dicts) / len(local_state_dicts)\n",
    "\n",
    "#     # Load averaged parameters into the server model\n",
    "#     server_model.load_state_dict(averaged_params)\n",
    "\n",
    "#     # Save the server model parameters to a file\n",
    "#     os.makedirs('textfiles', exist_ok=True)  # Ensure the directory exists\n",
    "#     torch.save(server_model.state_dict(), 'textfiles/serveriid_all.txt')\n",
    "\n",
    "#     return server_model\n",
    "\n",
    "\n",
    "\n",
    "# def server_averaging_non_iid(*local_models, device='cpu'):\n",
    "#     \"\"\"\n",
    "#     Averages the parameters of multiple local models to create a global model.\n",
    "\n",
    "#     Parameters:\n",
    "#     - *local_models: Variable number of trained local models (e.g., model_all1, model_all2).\n",
    "#     - device: The device ('cpu' or 'cuda') to perform computations on.\n",
    "\n",
    "#     Returns:\n",
    "#     - server_model: The globally averaged model.\n",
    "#     \"\"\"\n",
    "#     if len(local_models) < 2:\n",
    "#         raise ValueError(\"At least two models are required for averaging.\")\n",
    "    \n",
    "#     # Initialize the global model\n",
    "#     server_model = MLP().to(device)\n",
    "#     averaged_params = {}\n",
    "\n",
    "#     # Extract parameters and move to the specified device\n",
    "#     local_state_dicts = [model.state_dict() for model in local_models]\n",
    "\n",
    "#     # Parameter Averaging\n",
    "#     for key in local_state_dicts[0]:  # Iterate over the parameter keys\n",
    "#         averaged_params[key] = sum(local_state_dict[key] for local_state_dict in local_state_dicts) / len(local_state_dicts)\n",
    "\n",
    "#     # Load averaged parameters into the server model\n",
    "#     server_model.load_state_dict(averaged_params)\n",
    "\n",
    "#     # Save the server model parameters to a file\n",
    "#     os.makedirs('textfiles', exist_ok=True)  # Ensure the directory exists\n",
    "#     torch.save(server_model.state_dict(), 'textfiles/server_non_iid.txt')\n",
    "\n",
    "#     return server_model\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "def server_averaging_non_iid(*local_models, device='cpu'):\n",
    "    \"\"\"\n",
    "    Averages the parameters of multiple local models to create a global model.\n",
    "\n",
    "    Parameters:\n",
    "    - *local_models: Variable number of trained local models (e.g., model_all1, model_all2).\n",
    "    - device: The device ('cpu' or 'cuda') to perform computations on.\n",
    "\n",
    "    Returns:\n",
    "    - server_model: The globally averaged model.\n",
    "    \"\"\"\n",
    "    if len(local_models) < 2:\n",
    "        raise ValueError(\"At least two models are required for averaging.\")\n",
    "\n",
    "    # Ensure all local models are moved to the correct device and extract their state dictionaries\n",
    "    local_state_dicts = [model.to(device).state_dict() for model in local_models]\n",
    "\n",
    "    # Initialize the global model\n",
    "    server_model = MLP().to(device)\n",
    "    averaged_params = {}\n",
    "\n",
    "    # Check if all models have the same architecture (parameter shapes)\n",
    "    state_dict_keys = [list(model.state_dict().keys()) for model in local_models]\n",
    "    if any(keys != state_dict_keys[0] for keys in state_dict_keys):\n",
    "        raise ValueError(\"All models must have the same architecture (parameter shapes).\")\n",
    "\n",
    "    # Parameter Averaging\n",
    "    for key in local_state_dicts[0]:  # Iterate over the parameter keys\n",
    "        # Averaging the parameters of local models\n",
    "        averaged_params[key] = sum(local_state_dict[key].float() for local_state_dict in local_state_dicts) / len(local_state_dicts)\n",
    "        \n",
    "        # Optional: Remove rounding if it negatively affects performance\n",
    "        averaged_params[key] = averaged_params[key]  # You may want to remove rounding here\n",
    "\n",
    "    # Load averaged parameters into the server model\n",
    "    server_model.load_state_dict(averaged_params)\n",
    "\n",
    "    # Save the server model parameters to a file\n",
    "    os.makedirs('textfiles', exist_ok=True)  # Ensure the directory exists\n",
    "    torch.save(server_model.state_dict(), 'textfiles/server_non_iid.txt')\n",
    "\n",
    "    return server_model\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_non_iid(model, test_loader, client_loaders=None, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluates the accuracy of a global model on a test set and optionally per client.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The global model to evaluate.\n",
    "    - test_loader: DataLoader containing the global test dataset.\n",
    "    - client_loaders (optional): Dictionary of client DataLoaders to evaluate accuracy per client.\n",
    "    - device: The device ('cpu' or 'cuda') to run the evaluation on.\n",
    "\n",
    "    Returns:\n",
    "    - global_accuracy: The accuracy of the model on the global test dataset, in percentage.\n",
    "    - client_accuracies (if client_loaders provided): Dictionary with accuracy for each client.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Global test accuracy\n",
    "    correct_global = 0\n",
    "    total_global = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Update counts\n",
    "            total_global += labels.size(0)\n",
    "            correct_global += (predicted == labels).sum().item()\n",
    "\n",
    "    global_accuracy = 100.0 * correct_global / total_global if total_global > 0 else 0.0\n",
    "    print(f\"Global Test Accuracy: {global_accuracy:.2f}%\")\n",
    "\n",
    "    # Per-client accuracy (if client loaders are provided)\n",
    "    client_accuracies = {}\n",
    "    if client_loaders:\n",
    "        for client_id, client_loader in client_loaders.items():\n",
    "            correct_client = 0\n",
    "            total_client = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in client_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                    total_client += labels.size(0)\n",
    "                    correct_client += (predicted == labels).sum().item()\n",
    "\n",
    "            client_accuracy = 100.0 * correct_client / total_client if total_client > 0 else 0.0\n",
    "            client_accuracies[client_id] = client_accuracy\n",
    "            print(f\"Accuracy for {client_id}: {client_accuracy:.2f}%\")\n",
    "\n",
    "    return global_accuracy, client_accuracies if client_loaders else global_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non-iid simualtion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def NonIID_simulation(local_epochs, Global_round, lr, loader_client1, loader_client2, testloader):\n",
    "#     # Initialize the global model\n",
    "#     initial_model = MLP()\n",
    "    \n",
    "#     # Load pre-trained global model if available\n",
    "#     model_path = 'textfiles/server_non_iid.txt'\n",
    "#     if os.path.isfile(model_path):\n",
    "#         try:\n",
    "#             initial_model.load_state_dict(torch.load(model_path))\n",
    "#             print(\"Loaded saved global model weights.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading model weights: {e}. Starting with a new model.\")\n",
    "\n",
    "#     # Initialize local models\n",
    "#     local_models = {\"client_1\": MLP(), \"client_2\": MLP()}\n",
    "#     client_dataloaders = {\n",
    "#         \"client_1\": loader_client1,\n",
    "#         \"client_2\": loader_client2,\n",
    "#     }  # Combine loaders into a dictionary\n",
    "\n",
    "#     # Set the device (CPU or CUDA)\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     print(f\"Using device: {device}\")\n",
    "\n",
    "#     # Main simulation loop\n",
    "#     for i in range(Global_round):\n",
    "#         print(f\"\\nStarting Global Round {i + 1}...\")\n",
    "\n",
    "#         # Synchronize local models with the global model\n",
    "#         for client_id, model in local_models.items():\n",
    "#             model.load_state_dict(initial_model.state_dict())\n",
    "\n",
    "#         # Analyze data diversity across clients\n",
    "#         analyze_dataset_diversity(client_dataloaders)\n",
    "\n",
    "#         # Train the local models\n",
    "#         for client_id, model in local_models.items():\n",
    "#             print(f\"Training {client_id}...\")\n",
    "#             train_model(model, client_dataloaders[client_id], local_epochs, lr)\n",
    "\n",
    "#         # Evaluate local models\n",
    "#         client_performance = evaluate_local_models(local_models, client_dataloaders, criterion=torch.nn.CrossEntropyLoss())\n",
    "#         print(f\"Client Performance for Round {i + 1}: {client_performance}\")\n",
    "\n",
    "#         # Perform server averaging to update the global model\n",
    "#         initial_model = server_averaging_non_iid(*local_models.values())\n",
    "\n",
    "#         # Evaluate the global model on the test set\n",
    "#         acc = test_accuracy_non_iid(initial_model, testloader)\n",
    "#         if isinstance(acc, tuple):\n",
    "#             acc = acc[0]  # Get the first element, which should be the accuracy\n",
    "\n",
    "\n",
    "#         print(f'Global Round: {i + 1}, Global Model Accuracy: {acc:.2f}%')\n",
    "\n",
    "#         # Save the accuracy and global model weights for tracking\n",
    "#         os.makedirs('textfiles', exist_ok=True)\n",
    "#         with open('textfiles/accuracy_non_iid.txt', 'a') as f:\n",
    "#             f.write(f'Round {i + 1}: {acc:.2f}%\\n')\n",
    "        \n",
    "#         torch.save(initial_model.state_dict(), model_path)  # Save updated global model\n",
    "\n",
    "#     return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NonIID_simulation(local_epochs, Global_round, lr, loader_client1, loader_client2, testloader):\n",
    "    # Initialize the global model\n",
    "    initial_model = MLP()\n",
    "    \n",
    "    # Load pre-trained global model if available\n",
    "    model_path = 'textfiles/server_non_iid.txt'\n",
    "    if os.path.isfile(model_path):\n",
    "        try:\n",
    "            initial_model.load_state_dict(torch.load(model_path))\n",
    "            print(\"Loaded saved global model weights.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model weights: {e}. Starting with a new model.\")\n",
    "\n",
    "    # Initialize local models\n",
    "    local_models = {\"client_1\": MLP(), \"client_2\": MLP()}\n",
    "    client_dataloaders = {\n",
    "        \"client_1\": loader_client1,\n",
    "        \"client_2\": loader_client2,\n",
    "    }  # Combine loaders into a dictionary\n",
    "\n",
    "    # Set the device (CPU or CUDA)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Main simulation loop\n",
    "    for i in range(Global_round):\n",
    "        print(f\"\\nStarting Global Round {i + 1}...\")\n",
    "\n",
    "        # Train the local models on their own data without synchronizing with the global model yet\n",
    "        for client_id, model in local_models.items():\n",
    "            print(f\"Training {client_id}...\")\n",
    "            train_model(model, client_dataloaders[client_id], local_epochs, lr)\n",
    "\n",
    "        # Evaluate local models\n",
    "        client_performance = evaluate_model(local_models, client_dataloaders, criterion=torch.nn.CrossEntropyLoss())\n",
    "        print(f\"Client Performance for Round {i + 1}: {client_performance}\")\n",
    "\n",
    "        # Perform server averaging to update the global model\n",
    "        initial_model = server_averaging_non_iid(*local_models.values())\n",
    "\n",
    "        # Debugging: Check global model's parameters after averaging\n",
    "        print(\"Model parameters after averaging:\")\n",
    "        for key in initial_model.state_dict():\n",
    "            print(key)  # Print all parameter keys to find the correct one\n",
    "\n",
    "        # Evaluate the global model on the test set\n",
    "        acc = test_accuracy_non_iid(initial_model, testloader)\n",
    "        if isinstance(acc, tuple):\n",
    "            acc = acc[0]  # Get the first element, which should be the accuracy\n",
    "\n",
    "        print(f'Global Round: {i + 1}, Global Model Accuracy: {acc:.2f}%')\n",
    "\n",
    "        # Save the accuracy and global model weights for tracking\n",
    "        os.makedirs('textfiles', exist_ok=True)\n",
    "        with open('textfiles/accuracy_non_iid.txt', 'a') as f:\n",
    "            f.write(f'Round {i + 1}: {acc:.2f}%\\n')\n",
    "        \n",
    "        torch.save(initial_model.state_dict(), model_path)  # Save updated global model\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_models = {\n",
    "    'client1': MLP(),\n",
    "    'client2': MLP(),\n",
    "}\n",
    "run = NonIID_simulation(3, 20, 0.00001, loader_client1, loader_client2, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
